# Implemented thus far

- Transactional key-value storage on top of LevelDB
- Document storage on top of that
- Index storage on top of documents
- Etags per documents kept per version
- Wrapper around Lucene for index content
- Indexing process that executes 'maps' documents into Lucene
- Querying against the indexes, loading documents that match
- HTTP API around the above
- Basic client API around the HTTP API
- Bulk imports
- A rudimentary client-side session helper

# Pending/debt/etc

### Immediate priority
- Perform indexing in chunks (at the moment it's all or nothing)
- Allow restricting indexing to documents with a prefix (cats-/dogs-)
- Allow paging through results by some means
- Modification of an index means re-indexing


### Can wait

- Options for Lucene
- Decide on how to expose Lucene queries to the consumer
- Process to remove deleted documents from index
- Some form of concurrency check over transactions (MVCC most likely)
- Handle errors during indexing so it doesn't infini-loop
- The index engine shouldn't be swallowing agent exceptions
- Client should be handling HTTP results properly
- HTTP server should be sending back appropriate HTTP responses
- Documents should be validated as valid clojure objects by HTTP API
- Document storage should be responsible for serializing to string
- Allow indexes to be provided as actual functions (sfn macro) - this will make testing easier

